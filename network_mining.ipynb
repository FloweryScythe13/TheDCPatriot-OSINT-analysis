{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6792\n",
      "6662\n",
      "3857\n",
      "3827\n",
      "3364\n",
      "3274\n"
     ]
    }
   ],
   "source": [
    "trumpPOTUS_members = []\n",
    "rwb_trump_members = []\n",
    "woo_members = []\n",
    "DATA_DIR = 'data/fb_group_member_lists/'\n",
    "with open(DATA_DIR + 'TrumpPOTUS1.json','r') as f:\n",
    "    member = json.loads(f.read())\n",
    "    print(len(member['TrumpPOTUS']))\n",
    "    member_set = {frozenset(item.items()): item for item in member['TrumpPOTUS']}.values()\n",
    "    print(len(member_set))\n",
    "    trumpPOTUS_members = {v['link']: v for v in member_set}\n",
    "    # for i in member['TrumpPOTUS1']:\n",
    "    #     arr1.append(i['link'])\n",
    "    f.close()\n",
    "    \n",
    "with open(DATA_DIR + 'RedWhiteandWETHEPEOPLE.json', 'r') as f:\n",
    "    member = json.loads(f.read())\n",
    "    print(len(member['Red_White_and_WE_THE_PEOPLE']))\n",
    "    member_set = {frozenset(item.items()): item for item in member['Red_White_and_WE_THE_PEOPLE']}.values()\n",
    "    print(len(member_set))\n",
    "    rwb_trump_members = {v['link']: v for v in member_set}\n",
    "    # for i in member['TrumpPOTUS1']:\n",
    "    #     arr1.append(i['link'])\n",
    "    f.close()\n",
    "    \n",
    "with open(DATA_DIR + 'WoothePeople.json', 'r') as f:\n",
    "    member = json.loads(f.read())\n",
    "    print(len(member['Woo_the_People']))\n",
    "    member_set = {frozenset(item.items()): item for item in member['Woo_the_People']}.values()\n",
    "    print(len(member_set))\n",
    "    woo_members = {v['link']: v for v in member_set}\n",
    "    # for i in member['TrumpPOTUS1']:\n",
    "    #     arr1.append(i['link'])\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Woo the People', 'link': 'https://www.facebook.com/woothepeople/', 'profile_pic': 'https://scontent-lga3-2.xx.fbcdn.net/v/t1.6435-1/61009527_866896013663696_7985116086196502528_n.png?stp=cp0_dst-png_p60x60&_nc_cat=106&ccb=1-5&_nc_sid=1eb0c7&_nc_ohc=QSa2ivwAaCkAX_Ss7Z4&tn=eFsTMwWFOffHNwfJ&_nc_ht=scontent-lga3-2.xx&oh=00_AT8usvwZF8s_f68m9NksGj-G8QK5pQbS59dKQHGQVRahyg&oe=6287F0FE', 'role': 'admin/moderator'}\n"
     ]
    }
   ],
   "source": [
    "print(woo_members['https://www.facebook.com/woothepeople/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'str'>}\n",
      "5\n",
      "3\n",
      "59\n",
      "1\n",
      "4792\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mutual group members between the three groups\n",
    "mutual_friends = {'TrumpPOTUS-RWBTrump': [], 'TrumpPOTUS-Woo': [], 'RWBTrump-Woo': [], 'all': []}\n",
    "mutual_friends['TrumpPOTUS-RWBTrump'] = set(trumpPOTUS_members.keys()) & set(rwb_trump_members.keys())\n",
    "mutual_friends['TrumpPOTUS-Woo'] = set(trumpPOTUS_members.keys()) & set(woo_members.keys())\n",
    "mutual_friends['RWBTrump-Woo'] = set(rwb_trump_members.keys()) & set(woo_members.keys())\n",
    "members_set_list = [set(trumpPOTUS_members.keys()), set(rwb_trump_members.keys()), set(woo_members.keys())]\n",
    "# unpack the list of sets and pass all of them as arguments into intersection()\n",
    "mutual_friends['all'] = members_set_list[0].intersection(*members_set_list)\n",
    "\n",
    "print({type(intersect) for intersect in mutual_friends})\n",
    "print(len(mutual_friends['TrumpPOTUS-RWBTrump']))\n",
    "print(len(mutual_friends['TrumpPOTUS-Woo']))\n",
    "print(len(mutual_friends['RWBTrump-Woo']))\n",
    "print(len(mutual_friends['all']))\n",
    "print(len(trumpPOTUS_members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Extra, HttpUrl\n",
    "from typing import Optional, Any\n",
    "import shortuuid\n",
    "\n",
    "\n",
    "class Node(BaseModel):\n",
    "    _id: Optional[Any]\n",
    "    type: Optional[str]\n",
    "    name: str\n",
    "    link: str\n",
    "    \n",
    "    class Config:\n",
    "        extra = Extra.ignore\n",
    "    \n",
    "    def to_memgraph_format(self):\n",
    "            return {\n",
    "                \"id\": self._id,\n",
    "                \"properties\": {k: v for k, v in dict(self).items() if not k.startswith(\"_\")},\n",
    "                \"type\": \"node\"\n",
    "            }\n",
    "    \n",
    "\n",
    "class UserAccount(Node):\n",
    "    profile_pic: str\n",
    "    description: Optional[str]\n",
    "    # def __init__(self, **data):\n",
    "    #     super().__init__(self, **data)\n",
    "    #     self.type = \"User\"\n",
    "    #     self.photo = data.get(\"profile_pic\")\n",
    "    #     self.description = data.get(\"description\")\n",
    "        \n",
    "class Group(Node):\n",
    "    type = \"Group\"\n",
    "    # def __init(self, **data):\n",
    "    #     super().__init__(self, **data)\n",
    "    #     self.type = \"Group\"\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    _id: Optional[Any]\n",
    "    source: Optional[Any]\n",
    "    target: Optional[Any]\n",
    "    \n",
    "    class Config:\n",
    "        extra = Extra.allow\n",
    "        \n",
    "    def to_memgraph_format(self):\n",
    "            return {\n",
    "                \"id\": self._id,\n",
    "                \"start\": self.source,\n",
    "                \"end\": self.target,\n",
    "                \"label\": self.__class__.__name__,\n",
    "                \"properties\": {k: v for k, v in dict(self).items() if not k.startswith(\"_\")},\n",
    "                \"type\": \"relationship\"\n",
    "            }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_edges_output_list = {\"nodes\": [], \"edges\": []}\n",
    "\n",
    "# nodes_edges_output_list['nodes'].append(Group(id=1, name=\"PRESIDENT DONALD TRUMP\", link=\"https://www.facebook.com/groups/515283525287467/\").dict())\n",
    "# nodes_edges_output_list['nodes'].append(Group(id=2, name=\"RED, WHITE, and WE THE PEOPLE back the BLUE & PRESIDENT TRUMP\", link=\"https://www.facebook.com/groups/3838333272856171/\").dict())\n",
    "# nodes_edges_output_list['nodes'].append(Group(id=3, name=\"Woo the People\", link=\"https://www.facebook.com/groups/355954155643336/\").dict())\n",
    "\n",
    "# Expects input of the form {'group1_name': {'link': group1_link, 'members': group1_members_dict}, \n",
    "# 'group2_name': {'link': group2_link, 'members': group2_members_dict}, ...}\n",
    "# def populate_output_from_dicts(**kwargs):\n",
    "full_members_dict = {**trumpPOTUS_members, **rwb_trump_members, **woo_members}\n",
    "for value in full_members_dict.values():\n",
    "    value[\"id\"] = shortuuid.uuid()\n",
    "    nodes_edges_output_list[\"nodes\"].append(value)\n",
    "\n",
    "groups_dict = {\n",
    "    \"https://www.facebook.com/groups/[REDACTED]/\": {\n",
    "        \"name\": \"PRESIDENT DONALD TRUMP\", \n",
    "        \"id\": shortuuid.uuid(), \n",
    "        \"members\": trumpPOTUS_members, \n",
    "        \"link\": \"https://www.facebook.com/groups/[REDACTED]/\",\n",
    "        \"labels\": [\"Group\"]}, \n",
    "    \"https://www.facebook.com/groups/[REDACTED]/\": {\n",
    "        \"name\": \"RED, WHITE, and WE THE PEOPLE back the BLUE & PRESIDENT TRUMP\", \n",
    "        \"id\": shortuuid.uuid(), \n",
    "        \"members\": rwb_trump_members, \n",
    "        \"link\": \"https://www.facebook.com/groups/[REDACTED]/\",\n",
    "        \"labels\": [\"Group\"]\n",
    "    },\n",
    "    \"https://www.facebook.com/groups/[REDACTED]/\": {\n",
    "        \"name\": \"Woo the People\", \n",
    "        \"id\": shortuuid.uuid(), \n",
    "        \"members\": woo_members, \n",
    "        \"link\": \"https://www.facebook.com/groups/[REDACTED]/\",\n",
    "        \"labels\": [\"Group\"]}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for grp in groups_dict.values():\n",
    "    source_id = grp[\"id\"]\n",
    "    nodes_edges_output_list['nodes'].append(grp)\n",
    "    for k, v in grp[\"members\"].items():\n",
    "        # Here, rather than simply taking the dictionary item I've been given directly, I will \n",
    "        # use the item's key to retrieve the corresponding entry from full_members_dict (where there are no duplicate member entries), \n",
    "        # which contains the necessary id property for the member\n",
    "        member_node_id = full_members_dict[k][\"id\"]\n",
    "        nodes_edges_output_list['edges'].append({\"source\": source_id, \"target\": member_node_id, \"join_date\": v.get('joined')})\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "memgraph_import_list = []\n",
    "\n",
    "for node in nodes_edges_output_list['nodes']:\n",
    "    memgraph_node = None\n",
    "    if (\"UserAccount\" in node['labels']):\n",
    "        memgraph_node = UserAccount.parse_obj(node)\n",
    "    elif (\"Group\" in node['labels']):\n",
    "        memgraph_node = Group.parse_obj(node)\n",
    "    memgraph_import_list.append(memgraph_node)\n",
    "    \n",
    "for edge in nodes_edges_output_list['edges']:\n",
    "    edge['_id'] = shortuuid.uuid()\n",
    "    memgraph_edge = Relationship.parse_obj(edge)\n",
    "    memgraph_import_list.append(memgraph_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11829\n",
      "11892\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes_edges_output_list['nodes']))\n",
    "print(len(nodes_edges_output_list['edges']))\n",
    "memgraph_output = list(map(lambda x: x.to_memgraph_format(), memgraph_import_list))\n",
    "\n",
    "with open('data-temp/network.json', 'w') as f:\n",
    "    json.dump(nodes_edges_output_list, f, indent=4)\n",
    "with open('data-temp/memgraph-import.json', 'w') as f:\n",
    "    json.dump(memgraph_output, f, indent=4)\n",
    "# with open('nodes.json', 'w') as f:\n",
    "#     json.dump(nodes_edges_output_list['nodes'], f, indent=4)\n",
    "# with open('edges.json', 'w') as f:\n",
    "#     json.dump(nodes_edges_output_list['edges'], f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oops. A nodes-edges list works as an input format for D3, but not for ORA. ORA requires an adjacency matrix in CSV format.\n",
    "# Let's fix that. \n",
    "\n",
    "import numpy as np\n",
    "import networkx\n",
    "import pandas as pd \n",
    "\n",
    "n_nodes = len(nodes_edges_output_list[\"nodes\"])\n",
    "A = np.zeros((500,500))\n",
    "reduced_edges_list = []\n",
    "\n",
    "for grp in groups_dict.values():\n",
    "    source_id = grp[\"id\"]\n",
    "    for index, (k, v) in enumerate(grp[\"members\"].items()):\n",
    "        # Here, rather than simply taking the dictionary item I've been given directly, I will \n",
    "        # use the item's key to retrieve the corresponding entry from full_members_dict (where there are no duplicate member entries), \n",
    "        # which contains the necessary id property for the member\n",
    "        if index <= 1999:\n",
    "            member_node_id = full_members_dict[k][\"id\"]\n",
    "            reduced_edges_list.append({\"source\": source_id, \"target\": member_node_id, \"join_date\": v.get('joined')})\n",
    "        else:\n",
    "            break\n",
    "edges_df = pd.DataFrame(reduced_edges_list)\n",
    "G = networkx.from_pandas_edgelist(edges_df, edge_attr=True)\n",
    "\n",
    "reduced_nodes_list = []\n",
    "\n",
    "for node in G.nodes:\n",
    "    member_node_entry = nodes_edges_output_list[\"nodes\"][node]\n",
    "G.nodes = networkx.set_n\n",
    "# A = networkx.adjacency_matrix(G, weight=\"join_date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkx.write_weighted_edgelist(G, \"data-temp/network_ORA_reduced.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06978df5d7fdf2da75bbc77aec524566b5da5f95a69bdbf48b0bb60b6240550b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
